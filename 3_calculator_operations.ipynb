{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "939e2044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(model.invoke(\"Say hello\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09831699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divides two numbers.\"\"\"\n",
    "    return a / b\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "tools = [multiply, divide, add]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a71160db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import AnyMessage\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "import operator\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    llm_calls: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c30e0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import SystemMessage\n",
    "\n",
    "def llm_call(state: dict):\n",
    "    return {\n",
    "        \"messages\":[\n",
    "            model_with_tools.invoke(\n",
    "                [\n",
    "                    SystemMessage(\n",
    "                        content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n",
    "                    )\n",
    "                ]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ],\n",
    "        \"llm_calls\": state.get('llm_calls', 0) + 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b73cab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import ToolMessage\n",
    "\n",
    "def tool_node(state: dict):\n",
    "    result = []\n",
    "\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        result.append(ToolMessage(\n",
    "            content=observation,\n",
    "            tool_call_id=tool_call[\"id\"]\n",
    "        ))\n",
    "\n",
    "    return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e35106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tool_node\", END]:\n",
    "    \"\"\"Decide if we should continue the loop or stop based upon whether the LLM made a tool call\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # If the LLM makes a tool call, then perform an action\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool_node\"\n",
    "\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f50985df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tllm_call(llm_call)\n",
      "\ttool_node(tool_node)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> llm_call;\n",
      "\tllm_call -.-> __end__;\n",
      "\tllm_call -.-> tool_node;\n",
      "\ttool_node --> llm_call;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is 12 multiplied by 7, then divided by 3, and finally add 10?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (w39y2hb74)\n",
      " Call ID: w39y2hb74\n",
      "  Args:\n",
      "    a: 12\n",
      "    b: 7\n",
      "  divide (nttjb35r2)\n",
      " Call ID: nttjb35r2\n",
      "  Args:\n",
      "    a: 84\n",
      "    b: 3\n",
      "  add (5wp0ggfha)\n",
      " Call ID: 5wp0ggfha\n",
      "  Args:\n",
      "    a: 28\n",
      "    b: 10\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "84\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "28.0\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "38\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of the given arithmetic operations is 38.\n"
     ]
    }
   ],
   "source": [
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"tool_node\", tool_node)\n",
    "\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    [\"tool_node\", END]\n",
    ")\n",
    "agent_builder.add_edge(\"tool_node\", \"llm_call\")\n",
    "\n",
    "agent = agent_builder.compile()\n",
    "\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from IPython.display import display, Image\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# display(\n",
    "#     Image(\n",
    "#         agent.get_graph(xray=True).draw_mermaid_png(\n",
    "#             draw_method=MermaidDrawMethod.PYPPETEER\n",
    "#         )\n",
    "#     )\n",
    "# )\n",
    "\n",
    "print(agent.get_graph(xray=True).draw_mermaid())\n",
    "\n",
    "from langchain.messages import HumanMessage\n",
    "messages = [HumanMessage(content=\"What is 12 multiplied by 7, then divided by 3, and finally add 10?\")]\n",
    "messages = agent.invoke({\"messages\" : messages})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dilogs-ai-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
